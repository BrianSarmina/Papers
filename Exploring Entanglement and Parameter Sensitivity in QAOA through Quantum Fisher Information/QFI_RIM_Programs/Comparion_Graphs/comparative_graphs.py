# -*- coding: utf-8 -*-
"""Comparative_Graphs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-sJEwM20EaJoDdBKRNU52BHyphwb_oY2
"""

##!pip install pennylane
##!pip install qiskit
##!pip install qiskit_aer

import networkx as nx
import matplotlib.pyplot as plt
import numpy as np
import pennylane as qml
import re
import seaborn as sns
import numpy as np
import networkx as nx
import pickle, copy, re
from typing import List, Dict

# --- Qiskit ---
from qiskit import QuantumCircuit, transpile
from qiskit_aer import AerSimulator

import numpy as np, copy, pickle, networkx as nx, matplotlib.pyplot as plt
from itertools import product
from qiskit_aer import AerSimulator
from qiskit import QuantumCircuit, transpile
import random, math, os

############## RIM PROBLEMS ##############
problems = open('Random_Graphs_QFI.pkl','rb')
problems_data = pickle.load(problems)
problems.close()
print(problems_data)

############ LOADING RX-only DATA #############
rx_l1 = open('QFI_experiment_matrices_rx_L1.pkl','rb')
data_rx_l1 = pickle.load(rx_l1)
rx_l1.close()
rx_l2 = open('QFI_experiment_matrices_rx_L2.pkl','rb')
data_rx_l2 = pickle.load(rx_l2)
rx_l2.close()
rx_l3 = open('QFI_experiment_matrices_rx_L3.pkl','rb')
data_rx_l3 = pickle.load(rx_l3)
rx_l3.close()
rx_ent_l1 = open('QFI_experiment_matrices_rx_L1_ent.pkl','rb')
data_rx_ent_l1 = pickle.load(rx_ent_l1)
rx_ent_l1.close()
rx_ent_l2 = open('QFI_experiment_matrices_rx_L2_ent.pkl','rb')
data_rx_ent_l2 = pickle.load(rx_ent_l2)
rx_ent_l2.close()
rx_ent_l3 = open('QFI_experiment_matrices_rx_L3_ent.pkl','rb')
data_rx_ent_l3 = pickle.load(rx_ent_l3)
rx_ent_l3.close()
################## LOADING RX-RY DATA #############
rxry_l1 = open('QFI_experiment_matrices_rxry_L1.pkl','rb')
data_rxry_l1 = pickle.load(rxry_l1)
rxry_l1.close()
rxry_l2 = open('QFI_experiment_matrices_rxry_L2.pkl','rb')
data_rxry_l2 = pickle.load(rxry_l2)
rxry_l2.close()
rxry_l3 = open('QFI_experiment_matrices_rxry_L3.pkl','rb')
data_rxry_l3 = pickle.load(rxry_l3)
rxry_l3.close()
rxry_ent_l1 = open('QFI_experiment_matrices_rxry_L1_ent.pkl','rb')
data_rxry_ent_l1 = pickle.load(rxry_ent_l1)
rxry_ent_l1.close()
rxry_ent_l2 = open('QFI_experiment_matrices_rxry_L2_ent.pkl','rb')
data_rxry_ent_l2 = pickle.load(rxry_ent_l2)
rxry_ent_l2.close()
rxry_ent_l3 = open('QFI_experiment_matrices_rxry_L3_ent.pkl','rb')
data_rxry_ent_l3 = pickle.load(rxry_ent_l3)
rxry_ent_l3.close()

"""### QIM Heuristic for RIM problems"""

### QIm HEURISTIC ###
def qim_heuristic(i_state, capas, diag_norm_qfi_matrix):
  new_state = copy.copy(i_state)
  for i in range(len(new_state)):
    if np.random.random() <= diag_norm_qfi_matrix[i]:
      new_state[i] += (1-diag_norm_qfi_matrix[i]) * np.random.choice([-1, 1])
  return new_state

### non-QIm ###
def uniform_mutation(i_state, capas, diag_norm_qfi_matrix, size_step=0.01):
  new_state = copy.copy(i_state)
  for i in range(len(new_state)):
    if np.random.random() <= 0.5:
      new_state[i] += size_step * np.random.choice([-1, 1])
  return new_state

### Random Restarts ###
def random_restarts(i_state, capas, diag_norm_qfi_matrix, step_size=0.01):
  new_state = copy.copy(i_state)
  contador_rr = 0
  for i in range(len(new_state)-1):
    new_state[contador_rr] += step_size*np.random.uniform(0, np.pi)
    new_state[contador_rr+1] += step_size*np.random.uniform(0, 2*np.pi)
    contador_rr += 1
  return new_state

def qaoa(qc, q_num, edge_list, parametros, capas, simulador):
  contador = 0
  qc.h(range(q_num))
  qc.barrier()
  for i in range(capas):
    for edge in edge_list:
      qc.rzz(parametros[contador], edge[0], edge[1])
    qc.barrier()
    for j in range(q_num):
      qc.rx(parametros[contador+1], j)
    qc.barrier()
    contador += 2
  qc.measure_all()
  n_exp = 1024
  transpilado = transpile(qc, simulador)
  resultado = simulador.run(transpilado, shots=n_exp).result()
  counts = resultado.get_counts()
  costo = 0
  new_costo = 0
  for key, value in counts.items():
    costo = funcion_costo(key, edge_list)
    new_costo += (value * costo)/n_exp
  return qc, new_costo, parametros, counts

def funcion_costo(x, edge_list):
  costo = 0
  for con in edge_list:
    if x[con[0]] == x[con[1]]:
      costo += 0
    if x[con[0]] != x[con[1]]:
      costo += 1
  return costo

print(data_rx_l1[0][0])

# ============================================================
# EEV comparisons: QIm vs non-QIm vs RR
# Works with RX-only and RX-RY QFI datasets (L1/L2/L3)
# ============================================================

# -------------------- GLOBAL PLOT SETTINGS -----------------
FONT_SIZE = 14   # <--- change to adjust title/axis font sizes

plt.rcParams.update({
    "axes.titlesize": FONT_SIZE,
    "axes.labelsize": FONT_SIZE,
    "xtick.labelsize": FONT_SIZE - 2,
    "ytick.labelsize": FONT_SIZE - 2,
    "legend.fontsize": FONT_SIZE - 2
})

# -------------------- LOAD PROBLEMS ------------------------
with open('Random_Graphs_QFI.pkl','rb') as f:
    problems_data = pickle.load(f)
print(f"[INFO] Total problems: {len(problems_data)}")

# -------------------- LOAD QFI DATASETS --------------------
# RX-only (non-entangled)
with open('QFI_experiment_matrices_rx_L1.pkl','rb') as f: data_rx_l1 = pickle.load(f)
with open('QFI_experiment_matrices_rx_L2.pkl','rb') as f: data_rx_l2 = pickle.load(f)
with open('QFI_experiment_matrices_rx_L3.pkl','rb') as f: data_rx_l3 = pickle.load(f)
# RX-RY (non-entangled)
with open('QFI_experiment_matrices_rxry_L1.pkl','rb') as f: data_rxry_l1 = pickle.load(f)
with open('QFI_experiment_matrices_rxry_L2.pkl','rb') as f: data_rxry_l2 = pickle.load(f)
with open('QFI_experiment_matrices_rxry_L3.pkl','rb') as f: data_rxry_l3 = pickle.load(f)
# (Opcional) RX-only / RX-RY entangled datasets — activa si quieres incluirlos también
INCLUDE_ENTANGLED = True
if INCLUDE_ENTANGLED:
    with open('QFI_experiment_matrices_rx_L1_ent.pkl','rb') as f: data_rx_ent_l1 = pickle.load(f)
    with open('QFI_experiment_matrices_rx_L2_ent.pkl','rb') as f: data_rx_ent_l2 = pickle.load(f)
    with open('QFI_experiment_matrices_rx_L3_ent.pkl','rb') as f: data_rx_ent_l3 = pickle.load(f)
    with open('QFI_experiment_matrices_rxry_L1_ent.pkl','rb') as f: data_rxry_ent_l1 = pickle.load(f)
    with open('QFI_experiment_matrices_rxry_L2_ent.pkl','rb') as f: data_rxry_ent_l2 = pickle.load(f)
    with open('QFI_experiment_matrices_rxry_L3_ent.pkl','rb') as f: data_rxry_ent_l3 = pickle.load(f)

# -------------------- HYPERPARAMETERS ----------------------
N_TRIALS        = 10      # independent runs per problem
N_ITERS         = 50     # iterations (mutations) per run
STEP_NONQIM     = 0.01
STEP_RR         = 0.01
RANDOM_SEED     = 42
SAVE_PICKLE_PATH = "EEV_results.pkl"

np.random.seed(RANDOM_SEED)
random.seed(RANDOM_SEED)

# ============================================================
# HEURISTICS (your originals)
# ============================================================

def qim_heuristic(i_state, capas, diag_norm_qfi_matrix):
    new_state = copy.copy(i_state)
    for i in range(len(new_state)):
        if np.random.random() <= diag_norm_qfi_matrix[i]:
            new_state[i] += (1 - diag_norm_qfi_matrix[i]) * np.random.choice([-1, 1])
    return new_state

def uniform_mutation(i_state, capas, diag_norm_qfi_matrix, size_step=0.01):
    new_state = copy.copy(i_state)
    for i in range(len(new_state)):
        if np.random.random() <= 0.5:
            new_state[i] += size_step * np.random.choice([-1, 1])
    return new_state

def random_restarts(i_state, capas, diag_norm_qfi_matrix, step_size=0.01):
    new_state = copy.copy(i_state)
    contador_rr = 0
    for i in range(len(new_state)-1):
        new_state[contador_rr]   += step_size*np.random.uniform(0, np.pi)
        new_state[contador_rr+1] += step_size*np.random.uniform(0, 2*np.pi)
        contador_rr += 1
    return new_state

# ============================================================
# QAOA circuits: RX-only (rzz + rx) and RX-RY (rzz + rx + ry)
# ============================================================

def qaoa_rx(qc, q_num, edge_list, parametros, capas, simulador):
    """Per layer: RZZ on edges, then RX on all qubits. 2 params per layer."""
    contador = 0
    qc.h(range(q_num))
    qc.barrier()
    for _ in range(capas):
        for e in edge_list:
            qc.rzz(parametros[contador], e[0], e[1])
        qc.barrier()
        for j in range(q_num):
            qc.rx(parametros[contador+1], j)
        qc.barrier()
        contador += 2
    qc.measure_all()
    n_exp = 1024
    transpilado = transpile(qc, simulador)
    resultado = simulador.run(transpilado, shots=n_exp).result()
    counts = resultado.get_counts()
    new_costo = 0.0
    for bitstring, shots in counts.items():
        new_costo += shots * funcion_costo(bitstring, edge_list) / n_exp
    return new_costo

def qaoa_rxry(qc, q_num, edge_list, parametros, capas, simulador):
    """Per layer: RZZ on edges, then RX and RY on all qubits. 3 params per layer."""
    contador = 0
    qc.h(range(q_num))
    qc.barrier()
    for _ in range(capas):
        for e in edge_list:
            qc.rzz(parametros[contador], e[0], e[1])
        qc.barrier()
        for j in range(q_num):
            qc.rx(parametros[contador+1], j)
        qc.barrier()
        for j in range(q_num):
            qc.ry(parametros[contador+2], j)
        qc.barrier()
        contador += 3
    qc.measure_all()
    n_exp = 1024
    transpilado = transpile(qc, simulador)
    resultado = simulador.run(transpilado, shots=n_exp).result()
    counts = resultado.get_counts()
    new_costo = 0.0
    for bitstring, shots in counts.items():
        new_costo += shots * funcion_costo(bitstring, edge_list) / n_exp
    return new_costo

def funcion_costo(x, edge_list):
    # Max-Cut style: +1 for every edge cut
    costo = 0
    for (u, v) in edge_list:
        if x[u] != x[v]:
            costo += 1
    return costo

# ============================================================
# QFI helpers: average matrices per problem, normalize diag, infer p
# ============================================================

def qfi_list_to_mean_matrix(qfi_entry):
    """
    Your data shows: each problem entry is a list of N small 2x2 (or 4x4, 6x6) 'tensor(...)'
    objects. Convert each to numpy, stack and average.
    """
    np_mats = [np.array(m) for m in qfi_entry]  # robust: works even if not real torch tensors
    stack = np.stack(np_mats, axis=0)          # [k, d, d]
    return stack.mean(axis=0)                  # (d, d)

def diag_norm_from_qfi(Q):
    tr = np.trace(Q)
    if abs(tr) < 1e-12:
        return np.ones(Q.shape[0]) / Q.shape[0]
    return np.diag(Q) / tr

def infer_p_from_dim(dim, model):
    if model == 'rx':
        if dim % 2 != 0:
            raise ValueError(f"QFI dim {dim} not multiple of 2 for RX model.")
        return dim // 2
    elif model == 'rxry':
        if dim % 3 != 0:
            raise ValueError(f"QFI dim {dim} not multiple of 3 for RX-RY model.")
        return dim // 3
    else:
        raise ValueError(f"Unknown model: {model}")

# ============================================================
# One run (best EEV) for a given problem/method/model
# ============================================================

def run_single_problem(G, q_num, edge_list, qfi_matrix, model, method,
                       n_iters, simulador, seed=None):
    """
    Returns the best EEV achieved over n_iters with a single mutation chain.
    """
    if seed is not None:
        np.random.seed(seed); random.seed(seed)

    dim = qfi_matrix.shape[0]
    p_layers = infer_p_from_dim(dim, model)
    diag_norm = diag_norm_from_qfi(qfi_matrix)

    # initialize params: 2p (rx) or 3p (rxry)
    if model == 'rx':
        params = np.asarray([[np.random.uniform(0,np.pi), np.random.uniform(0,2*np.pi)]
                             for _ in range(p_layers)]).flatten()
        per_layer_params = 2
    else:  # rxry
        params = np.asarray([[np.random.uniform(0,np.pi),
                               np.random.uniform(0,2*np.pi),
                               np.random.uniform(0,2*np.pi)]
                             for _ in range(p_layers)]).flatten()
        per_layer_params = 3

    best = -np.inf
    curr = params.copy()

    for _ in range(n_iters):
        qc = QuantumCircuit(q_num)
        if model == 'rx':
            eev = qaoa_rx(qc, q_num, edge_list, curr, p_layers, simulador)
        else:
            eev = qaoa_rxry(qc, q_num, edge_list, curr, p_layers, simulador)
        if eev > best:
            best = eev

        # mutate
        if method == 'QIm':
            curr = qim_heuristic(curr, p_layers, diag_norm)
        elif method == 'nonQIm':
            curr = uniform_mutation(curr, p_layers, diag_norm, size_step=STEP_NONQIM)
        elif method == 'RR':
            curr = random_restarts(curr, p_layers, diag_norm, step_size=STEP_RR)
        else:
            raise ValueError("Unknown method")

    return best, p_layers

# ============================================================
# Evaluate all models, all methods, all problems
# ============================================================

def evaluate_all_models():
    simulador = AerSimulator()

    # Register which datasets to run (non-ent by default)
    models = {
        'RX_L1':  ('rx',   data_rx_l1),
        'RX_L2':  ('rx',   data_rx_l2),
        'RX_L3':  ('rx',   data_rx_l3),
        'RXRY_L1':('rxry', data_rxry_l1),
        'RXRY_L2':('rxry', data_rxry_l2),
        'RXRY_L3':('rxry', data_rxry_l3),
    }
    if INCLUDE_ENTANGLED:
        models.update({
            'RX_L1_ent':   ('rx',   data_rx_ent_l1),
            'RX_L2_ent':   ('rx',   data_rx_ent_l2),
            'RX_L3_ent':   ('rx',   data_rx_ent_l3),
            'RXRY_L1_ent': ('rxry', data_rxry_ent_l1),
            'RXRY_L2_ent': ('rxry', data_rxry_ent_l2),
            'RXRY_L3_ent': ('rxry', data_rxry_ent_l3),
        })

    methods = ['QIm', 'nonQIm', 'RR']

    results = {}  # results[model_name][method] = list of dicts per problem with stats
    for model_name, (model_kind, dataset) in models.items():
        print(f"\n[MODEL] {model_name} ({model_kind})")
        results[model_name] = {m: [] for m in methods}

        for prob_idx, (G, n) in enumerate(problems_data):
            edge_list = list(G.edges())

            # QFI mean matrix for this problem
            qfi_matrix = qfi_list_to_mean_matrix(dataset[prob_idx])
            dim = qfi_matrix.shape[0]
            p_layers = infer_p_from_dim(dim, model_kind)

            # run multiple trials for each method
            for m in methods:
                bests = []
                for t in range(N_TRIALS):
                    seed = RANDOM_SEED + 1000*prob_idx + 10*t + hash(m) % 7
                    best, _ = run_single_problem(
                        G, n, edge_list, qfi_matrix, model_kind, m, N_ITERS, simulador, seed=seed
                    )
                    bests.append(best)
                entry = {
                    'problem_index': prob_idx,
                    'n': n,
                    'p': p_layers,
                    'qfi_shape': dim,
                    'bests': bests,
                    'mean': float(np.mean(bests)),
                    'std':  float(np.std(bests)),
                    'min':  float(np.min(bests)),
                    'max':  float(np.max(bests)),
                }
                results[model_name][m].append(entry)

            print(f"  Problem {prob_idx+1}/{len(problems_data)} | n={n}, p={p_layers}, dim={dim}  "
                  f"| means  QIm={results[model_name]['QIm'][-1]['mean']:.3f}  "
                  f"nonQIm={results[model_name]['nonQIm'][-1]['mean']:.3f}  "
                  f"RR={results[model_name]['RR'][-1]['mean']:.3f}")

    return results

# ============================================================
# Plot helpers
# ============================================================

def plot_boxplots_by_model(results):
    """One boxplot per model comparing QIm vs nonQIm vs RR."""
    for model_name, per_method in results.items():
        data_box, labels = [], []
        for m in ['QIm','nonQIm','RR']:
            vals = []
            for entry in per_method[m]:
                vals.extend(entry['bests'])
            data_box.append(vals); labels.append(m)
        plt.figure(figsize=(7,6))
        plt.boxplot(data_box, labels=labels, showmeans=True)
        plt.title(f"Best EEV per trial — {model_name}")
        plt.ylabel("EEV")
        plt.grid(True, axis='y', alpha=0.3)
        plt.show()

def plot_series_first_few(results, k=3):
    """
    For quick visual sanity check: first k problems of each model,
    plot mean EEV per method across trials.
    """
    for model_name, per_method in results.items():
        # Build per-problem means per method
        means = {m: [entry['mean'] for entry in per_method[m]] for m in ['QIm','nonQIm','RR']}
        num_probs = min(k, len(means['QIm']))
        x = np.arange(num_probs)
        plt.figure(figsize=(9,5))
        plt.plot(x, means['QIm'][:num_probs],    marker='o', label='QIm')
        plt.plot(x, means['nonQIm'][:num_probs], marker='o', label='non-QIm')
        plt.plot(x, means['RR'][:num_probs],     marker='o', label='RR')
        plt.title(f"Mean best EEV (first {num_probs} problems) — {model_name}")
        plt.xlabel("Problem index")
        plt.ylabel("Mean Best EEV")
        plt.grid(True, alpha=0.3)
        plt.legend()
        plt.show()

# ============================================================
# MAIN
# ============================================================

if __name__ == "__main__":
    results = evaluate_all_models()

    # Save to pickle for later reuse
    with open(SAVE_PICKLE_PATH, 'wb') as f:
        pickle.dump(results, f)
    print(f"\n[INFO] Results saved to: {os.path.abspath(SAVE_PICKLE_PATH)}")

    # Plots
    plot_boxplots_by_model(results)
    plot_series_first_few(results, k=3)

# ############## RIM PROBLEMS ##############
# datos_resultados = open('EEV_results_mod_50_ent.pkl','rb')
# results = pickle.load(datos_resultados)
# datos_resultados.close()
# print(results)

# ############### BOX PLOTS ######################
# def plot_boxplots_grid(results, models_order=None, suptitle="Best EEV (per trial)"):
#     """
#     Draws a 2x3 grid of boxplots, one subplot per model, comparing QIm vs non-QIm vs RR.
#     - results: dict returned by evaluate_all_models()
#       results[model_name][method] -> list of entries with 'bests' per problem
#     - models_order: optional list to control which 6 models and their order.
#       Default: ['RX_L1','RX_L2','RX_L3','RXRY_L1','RXRY_L2','RXRY_L3']
#     """
#     # default order (six canonical models)
#     if models_order is None:
#         models_order = ['RX_L1_ent','RX_L2_ent','RX_L3_ent','RXRY_L1_ent','RXRY_L2_ent','RXRY_L3_ent']

#     # keep only models that actually exist in results
#     models = [m for m in models_order if m in results]
#     # ensure we have up to 6 slots; if fewer, we'll hide the extras
#     n_slots = 6
#     rows, cols = 2, 3

#     # gather global y-lims for fair comparison
#     all_vals = []
#     for m in models:
#         for method in ['QIm','nonQIm','RR']:
#             vals = []
#             for entry in results[m][method]:
#                 vals.extend(entry['bests'])
#             if len(vals):
#                 all_vals.extend(vals)
#     y_min = min(all_vals) if all_vals else 0.0
#     y_max = max(all_vals) if all_vals else 1.0
#     if y_min == y_max:
#         y_min -= 0.5
#         y_max += 0.5

#     fig, axes = plt.subplots(rows, cols, figsize=(18, 8), squeeze=False)
#     axes = axes.flatten()

#     for i in range(n_slots):
#         ax = axes[i]
#         if i < len(models):
#             model_name = models[i]
#             # build data for this model
#             data_box, labels = [], []
#             for method in ['QIm','nonQIm','RR']:
#                 vals = []
#                 for entry in results[model_name][method]:
#                     vals.extend(entry['bests'])
#                 data_box.append(vals)
#                 labels.append(method)

#             # draw boxplot
#             ax.boxplot(data_box, labels=labels, showmeans=True)
#             ax.set_title(model_name)
#             ax.set_ylim(y_min, y_max)
#             ax.grid(True, axis='y', alpha=0.3)
#             # put y-label only on left column
#             if i % cols == 0:
#                 ax.set_ylabel("EEV")
#         else:
#             # hide unused axes
#             ax.axis('off')

#     plt.suptitle(suptitle, fontsize=FONT_SIZE + 2)
#     plt.tight_layout(rect=[0, 0.03, 1, 0.96])
#     plt.savefig('QFI_box_plots_RIMS_50_ent.eps', format='eps')
#     plt.savefig('QFI_box_plots_RIM_50_ent.png', format='png', dpi=600)
#     plt.show()

# # -------------------- GLOBAL PLOT SETTINGS -----------------
# FONT_SIZE = 20   # <--- change to adjust title/axis font sizes

# plt.rcParams.update({
#     "axes.titlesize": FONT_SIZE,
#     "axes.labelsize": FONT_SIZE - 1,
#     "xtick.labelsize": FONT_SIZE - 2,
#     "ytick.labelsize": FONT_SIZE - 2,
#     "legend.fontsize": FONT_SIZE - 5
# })

# # Plots
# plot_boxplots_grid(results)
# # plot_series_all_models_one_figure(results, k=15)

# def plot_mean_eev_faceted(results, k=15, models_order=None,
#                           suptitle="Mean Best EEV"):
#     import numpy as np
#     import matplotlib.pyplot as plt
#     from matplotlib.lines import Line2D

#     if models_order is None:
#         models_order = ['RX_L1_ent','RX_L2_ent','RX_L3_ent','RXRY_L1_ent','RXRY_L2_ent','RXRY_L3_ent']
#     models = [m for m in models_order if m in results]
#     if not models:
#         print("[WARN] No models found.")
#         return

#     # estilos por método
#     methods = ['QIm','nonQIm','RR']
#     linestyle = {'QIm':'-','nonQIm':'--','RR':':'}
#     alpha_map = {'QIm':1.0,'nonQIm':0.9,'RR':0.9}
#     base_colors = plt.rcParams['axes.prop_cycle'].by_key().get('color', ['C0','C1','C2'])
#     color_map = dict(zip(methods, base_colors))

#     # etiquetas de problemas (ajusta según tu dataset real)
#     problem_blocks = [
#         ("W-S (6-nodes)", 5),
#         ("E-R (7-nodes)", 5),
#         ("B-A (8-nodes)", 5)
#     ]
#     total_problems = sum(size for _, size in problem_blocks)

#     # calcular límites globales
#     y_all = []
#     for model in models:
#         for m in methods:
#             arr = [e['mean'] for e in results[model][m]][:k]
#             y_all += arr
#     y_min = min(y_all) if y_all else 0.0
#     y_max = max(y_all) if y_all else 1.0
#     if y_min == y_max:
#         y_min -= 0.5; y_max += 0.5

#     rows, cols = 2, 3
#     fig, axes = plt.subplots(rows, cols, figsize=(18, 8), squeeze=False)
#     axes = axes.flatten()

#     for i, model in enumerate(models):
#         ax = axes[i]
#         for m in methods:
#             means = [entry['mean'] for entry in results[model][m]][:k]
#             stds  = [entry['std']  for entry in results[model][m]][:k]
#             x = np.arange(len(means))
#             if len(x)==0: continue

#             ax.plot(x, means, linestyle=linestyle[m], color=color_map[m],
#                     lw=2, alpha=alpha_map[m], label=m)
#             lo = np.array(means) - np.array(stds)
#             hi = np.array(means) + np.array(stds)
#             ax.fill_between(x, lo, hi, color=color_map[m], alpha=0.15, linewidth=0)

#         ax.set_title(model, fontsize=FONT_SIZE)
#         if i % cols == 0:
#             ax.set_ylabel("Mean Best EEV", fontsize=FONT_SIZE-2)
#         ax.grid(True, alpha=0.3)
#         ax.set_ylim(y_min-0.5, y_max+0.5)

#         # colocar etiquetas personalizadas en el eje x
#         tick_positions = []
#         tick_labels = []
#         pos = 0
#         for label, size in problem_blocks:
#             center = pos + size/2 - 0.5
#             tick_positions.append(center)
#             tick_labels.append(label)
#             # línea punteada al final del bloque
#             ax.axvline(pos + size - 0.5, color="black", linestyle=":", lw=1, alpha=0.7)
#             pos += size

#         ax.set_xticks(tick_positions)
#         ax.set_xticklabels(tick_labels, rotation=20, ha="right", fontsize=FONT_SIZE-7)

#     # leyenda global, movida más abajo
#     handles = [Line2D([0],[0], color=color_map[m], lw=3, linestyle=linestyle[m]) for m in methods]
#     labels  = methods
#     fig.legend(handles, labels, title="Methods", loc="lower center", ncol=3, frameon=True, bbox_to_anchor=(0.5, -0.05), fontsize=FONT_SIZE-2)
#     plt.suptitle(suptitle, fontsize=FONT_SIZE+2)
#     plt.tight_layout(rect=[0, 0.08, 1, 0.96])
#     plt.savefig('QFI_trend_and_series_RIMS_50_ent.eps', format='eps', bbox_inches='tight')
#     plt.savefig('QFI_trend_and_series_RIMS_50_ent.png', format='png', bbox_inches='tight', dpi=600)
#     plt.show()

# FONT_SIZE = 20   # <--- change to adjust title/axis font sizes
# plot_mean_eev_faceted(results, k=15)

# """### RIM QFI GRAPHS ###"""

# # ───────────────────────────────────────────
# # Colores y funciones auxiliares
# # ───────────────────────────────────────────
# COLOR_MAP = {
#     'RX'         : '#7EC8E3',  # light blue
#     'RX-ent'     : '#1F4E79',  # navy blue
#     'RX-RY'      : '#FDB27E',  # light orange
#     'RX-RY-ent'  : '#C25B00',  # dark orange
# }
# MODEL_ORDER = ['RX', 'RX-ent', 'RX-RY', 'RX-RY-ent']
# DEPTH_MARK = {1:'o', 2:'s', 3:'^'}

# legend_kwargs = dict(
#     frameon=True,
#     fontsize=12,
#     ncol=2,
#     facecolor='white',
#     edgecolor='black',
#     framealpha=0.9,     # opacidad del fondo
#     borderpad=0.8       # espacio interno
# )

# def parse_cfg(cfg_name: str):
#     base = 'RX-RY' if 'RX-RY' in cfg_name else 'RX'
#     model = base + ('-ent' if 'ent' in cfg_name else '')
#     m = re.search(r'L(\d+)', cfg_name)
#     depth = int(m.group(1)) if m else 1
#     return model, depth

# # Datos disponibles
# models_present = sorted({parse_cfg(c)[0] for c in summary}, key=MODEL_ORDER.index)
# depths_present = sorted({parse_cfg(c)[1] for c in summary})
# bar_width = 0.18

# # ───────────────────────────────────────────
# # Crear figura de 4 subplots
# # ───────────────────────────────────────────
# fig, axes = plt.subplots(2, 2, figsize=(15, 10))
# axes = axes.flatten()

# # ────────── 1. Trace vs Depth ──────────
# ax = axes[0]
# for i, model in enumerate(MODEL_ORDER):
#     if model not in models_present:
#         continue
#     means, stds = [], []
#     for d in depths_present:
#         cfgs = [c for c in summary if parse_cfg(c) == (model, d)]
#         if cfgs:
#             dat = summary[cfgs[0]]['trace']
#             means.append(np.nanmean(dat))
#             stds.append(np.nanstd(dat))
#         else:
#             means.append(np.nan)
#             stds.append(0.0)
#     x = np.array(depths_present) + (i - (len(MODEL_ORDER)-1)/2) * bar_width
#     ax.bar(x, means, bar_width, yerr=stds, capsize=3,
#            color=COLOR_MAP[model], alpha=0.9, label=model)
# ax.set_xticks(depths_present)
# ax.set_xlabel('Circuit Depth L', fontsize=14)
# ax.set_ylabel(r'Average $\mathrm{Tr}\,F$', fontsize=14)
# ax.set_title('Global Sensitivity (Trace of QFI)', fontsize=16)
# ax.grid(axis='y', alpha=.3)
# ax.legend(frameon=True, ncol=2, fontsize=12)

# # ────────── 2. Covariance Fraction vs Depth ──────────
# ax = axes[1]
# for i, model in enumerate(MODEL_ORDER):
#     if model not in models_present:
#         continue
#     means, stds = [], []
#     for d in depths_present:
#         cfgs = [c for c in summary if parse_cfg(c) == (model, d)]
#         if cfgs:
#             dat = summary[cfgs[0]]['covfrac']
#             means.append(np.nanmean(dat))
#             stds.append(np.nanstd(dat))
#         else:
#             means.append(np.nan)
#             stds.append(0.0)
#     x = np.array(depths_present) + (i - (len(MODEL_ORDER)-1)/2) * bar_width
#     ax.bar(x, means, bar_width, yerr=stds, capsize=3,
#            color=COLOR_MAP[model], alpha=0.9, label=model)
# ax.set_xticks(depths_present)
# ax.set_xlabel('Circuit Depth L', fontsize=14)
# ax.set_ylabel('Average Covariance Fraction', fontsize=14)
# ax.set_title('Cross-Parameter Coupling', fontsize=16)
# ax.grid(axis='y', alpha=.3)
# ax.legend(frameon=True, ncol=2, fontsize=12)

# # ────────── 3. Scatter (Trace vs Covariance Fraction) ──────────
# ax = axes[2]
# handles_dict = {}
# for cfg, data in summary.items():
#     model, depth = parse_cfg(cfg)
#     if model not in MODEL_ORDER:
#         continue
#     sc = ax.scatter(data['trace'], data['covfrac'],
#                     c=COLOR_MAP[model], marker=DEPTH_MARK.get(depth, 'o'),
#                     edgecolors='k', linewidths=.35, s=50,
#                     label=f'{model} L{depth}')
#     if f'{model} L{depth}' not in handles_dict:
#         handles_dict[f'{model} L{depth}'] = sc
# ax.set_xlabel(r'$\mathrm{Tr}\,F$', fontsize=14)
# ax.set_ylabel('Covariance Fraction', fontsize=14)
# ax.set_title('(γ, β) Landscape Points', fontsize=16)
# ax.set_xlim(0, 850)
# # ax.set_ylim(-0.1, 0.8)
# ax.grid(alpha=.25)
# ax.legend(handles=list(handles_dict.values()),
#           labels=list(handles_dict.keys()),
#           fontsize=10, frameon=True, ncol=2)

# # ────────── 4. Boxplot of λ_max ──────────
# ax = axes[3]
# cfg_order = sorted(summary.keys(), key=lambda c: (MODEL_ORDER.index(parse_cfg(c)[0]),
#                                                   parse_cfg(c)[1]))
# eig_data = [summary[c]['eigmax'] for c in cfg_order]
# palette = [COLOR_MAP[parse_cfg(c)[0]] for c in cfg_order]
# sns.boxplot(data=eig_data, ax=ax, palette=palette,
#             showcaps=True, showfliers=False, width=0.6)
# ax.set_xticklabels(cfg_order, rotation=45, ha='right', fontsize=9)
# ax.set_ylabel(r'Maximum Eigenvalue $\lambda_{\max}(F)$', fontsize=14)
# ax.set_title('Distribution of Largest Eigenvalue', fontsize=16)
# ax.grid(axis='y', alpha=.3)

# plt.tight_layout()
# plt.savefig("QFI_models_comparison.eps")
# plt.show()
